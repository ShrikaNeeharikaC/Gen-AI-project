CI/CD Prompt Evaluation Results
==================================================
Prompt ID  Score     
0          0.6635    
1          0.6138    
2          0.7148    
3          0.7030    
4          0.6407    

Best Prompt: #2 (Score: 0.7148)

⚠️  Best score is below 0.8. Suggested Actionable Items to Improve Prompts:
1. Review clarity and specificity: Ensure the prompt clearly defines the task, expected output format, and any constraints.
2. Add or improve context: Provide relevant background information or examples to help the model understand the scenario.
3. Refine structure: Use structured, numbered instructions and explicit field headers for each required output.
4. Encourage step-by-step reasoning: Ask the model to explain its reasoning or cite log evidence for conclusions.
5. Balance brevity and detail: Remove unnecessary verbosity, but do not omit essential guidance.
6. Include explicit evaluation criteria: Indicate how outputs will be judged (e.g., accuracy, completeness, format adherence).
7. Test with varied incidents: Evaluate prompt on diverse incident types to find weaknesses and edge cases.
8. Iterate and compare: Make small prompt changes, re-evaluate, and keep the best-performing versions.
